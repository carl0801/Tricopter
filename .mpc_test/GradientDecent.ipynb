{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle x_{7}^{2} + \\left(x_{0} + 2\\right)^{2} + \\left(x_{1} + 2\\right)^{2} + \\left(x_{2} + 5\\right)^{2} + \\left(x_{3} + 2\\right)^{2} + \\left(x_{4} + 4\\right)^{2} + \\left(x_{5} - 5\\right)^{2} + \\left(x_{6} + 1\\right)^{2} + \\left(x_{8} + 2\\right)^{2} + \\left(x_{9} - 1\\right)^{2}$"
      ],
      "text/plain": [
       "x7**2 + (x0 + 2)**2 + (x1 + 2)**2 + (x2 + 5)**2 + (x3 + 2)**2 + (x4 + 4)**2 + (x5 - 5)**2 + (x6 + 1)**2 + (x8 + 2)**2 + (x9 - 1)**2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}2 x_{0} + 4\\\\2 x_{1} + 4\\\\2 x_{2} + 10\\\\2 x_{3} + 4\\\\2 x_{4} + 8\\\\2 x_{5} - 10\\\\2 x_{6} + 2\\\\2 x_{7}\\\\2 x_{8} + 4\\\\2 x_{9} - 2\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[ 2*x0 + 4],\n",
       "[ 2*x1 + 4],\n",
       "[2*x2 + 10],\n",
       "[ 2*x3 + 4],\n",
       "[ 2*x4 + 8],\n",
       "[2*x5 - 10],\n",
       "[ 2*x6 + 2],\n",
       "[     2*x7],\n",
       "[ 2*x8 + 4],\n",
       "[ 2*x9 - 2]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The number of free_symbols in the expression is greater than 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[137], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m fd_lambda \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mlambdify(x, fd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Plot the function\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplotting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot3d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sympy\\plotting\\plot.py:2323\u001b[0m, in \u001b[0;36mplot3d\u001b[1;34m(show, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2321\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(sympify, args))\n\u001b[0;32m   2322\u001b[0m series \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 2323\u001b[0m plot_expr \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_arguments\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2324\u001b[0m series \u001b[38;5;241m=\u001b[39m [SurfaceOver2DRangeSeries(\u001b[38;5;241m*\u001b[39marg, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m plot_expr]\n\u001b[0;32m   2325\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m, series[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvar_x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sympy\\plotting\\plot.py:2606\u001b[0m, in \u001b[0;36mcheck_arguments\u001b[1;34m(args, expr_len, nb_of_free_symbols)\u001b[0m\n\u001b[0;32m   2602\u001b[0m free_symbols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m()\u001b[38;5;241m.\u001b[39munion(\u001b[38;5;241m*\u001b[39m[e\u001b[38;5;241m.\u001b[39mfree_symbols \u001b[38;5;28;01mfor\u001b[39;00m expr \u001b[38;5;129;01min\u001b[39;00m exprs\n\u001b[0;32m   2603\u001b[0m                                 \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m expr]))\n\u001b[0;32m   2605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(free_symbols) \u001b[38;5;241m>\u001b[39m nb_of_free_symbols:\n\u001b[1;32m-> 2606\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of free_symbols in the expression \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2607\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis greater than \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m nb_of_free_symbols)\n\u001b[0;32m   2608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m i \u001b[38;5;241m+\u001b[39m nb_of_free_symbols \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[i], Tuple):\n\u001b[0;32m   2609\u001b[0m     ranges \u001b[38;5;241m=\u001b[39m Tuple(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(args[\n\u001b[0;32m   2610\u001b[0m                    i:i \u001b[38;5;241m+\u001b[39m nb_of_free_symbols]))\n",
      "\u001b[1;31mValueError\u001b[0m: The number of free_symbols in the expression is greater than 2"
     ]
    }
   ],
   "source": [
    "f = sp.Function('f')\n",
    "variables = 10\n",
    "x = sp.Matrix([0]*variables)\n",
    "for i in range(variables):\n",
    "    exec(f\"x{i} = sp.symbols('x{i}')\")\n",
    "    x[i] = eval(f\"x{i}\")\n",
    "#f = (x0**2 + x1**2)+sp.sin(x0)+sp.cos(x1)\n",
    "#f = (1-x0)**2 + 100*(x1-x0**2)**2\n",
    "f = (x0+2)**2 + (x1+2)**2 + (x2+5)**2 + (x3+2)**2 + (x4+4)**2 + (x5-5)**2 + (x6+1)**2 + (x7)**2 + (x8+2)**2 + (x9-1)**2\n",
    "display(f)\n",
    "fd = f.diff(x)\n",
    "display(fd)\n",
    "# Lambda function\n",
    "f_lambda = sp.lambdify(x, f, 'numpy')\n",
    "fd_lambda = sp.lambdify(x, fd, 'numpy')\n",
    "# Plot the function\n",
    "sp.plotting.plot3d(f, (x0, -5, 5), (x1, -5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line search, a = 0.8, cost = 97684.0, newCost = 35166.24\n",
      "Iteration 1, x = [10. 10. 10. 10. 10. 10. 10. 10. 10. 10.], gradient = 625.09, velocity = 500.07, tol = 625.0887936925442\n",
      "Iteration 2, x = [ -7.63  -7.63 -10.    -7.63 -10.     3.68  -6.02  -4.4   -7.63  -2.78], gradient = 72.77, velocity = 53.4, tol = 72.77362159464101\n",
      "Iteration 3, x = [-0.6  -0.6  -3.82 -0.6  -2.53  5.31  0.24  1.09 -0.6   1.93], gradient = 31.53, velocity = 19.65, tol = 31.525165059044504\n",
      "Iteration 4, x = [-1.96 -1.96 -4.97 -1.96 -3.96  5.01 -0.97  0.03 -1.96  1.02], gradient = 7.77, velocity = 3.78, tol = 7.768436077564141\n",
      "Iteration 5, x = [-2.01 -2.01 -5.01 -2.01 -4.01  5.   -1.01 -0.01 -2.01  1.  ], gradient = 0.21, velocity = 0.12, tol = 0.206517667531556\n",
      "Iteration 6, x = [-2. -2. -5. -2. -4.  5. -1. -0. -2.  1.], gradient = 0.04, velocity = 0.01, tol = 0.038307854542657\n",
      "Iteration 7, x = [-2. -2. -5. -2. -4.  5. -1. -0. -2.  1.], gradient = 0.02, velocity = 0.0, tol = 0.01564817660434174\n",
      "Iteration 8, x = [-2. -2. -5. -2. -4.  5. -1. -0. -2.  1.], gradient = 0.01, velocity = 0.0, tol = 0.007217438391401031\n",
      "Iteration 9, x = [-2. -2. -5. -2. -4.  5. -1. -0. -2.  1.], gradient = 0.0, velocity = 0.0, tol = 0.0041059179488877745\n",
      "Iteration 10, x = [-2. -2. -5. -2. -4.  5. -1. -0. -2.  1.], gradient = 0.0, velocity = 0.0, tol = 0.0026970852983344137\n",
      "Iteration 11, x = [-2. -2. -5. -2. -4.  5. -1. -0. -2.  1.], gradient = 0.0, velocity = 0.0, tol = 0.001959003649898851\n",
      "Iteration 12, x = [-2. -2. -5. -2. -4.  5. -1. -0. -2.  1.], gradient = 0.0, velocity = 0.0, tol = 0.001530930002961232\n",
      "Iteration 13, x = [-2. -2. -5. -2. -4.  5. -1. -0. -2.  1.], gradient = 0.0, velocity = 0.0, tol = 0.0012636374946847992\n",
      "Iteration 14, x = [-2. -2. -5. -2. -4.  5. -1. -0. -2.  1.], gradient = 0.0, velocity = 0.0, tol = 0.0010872915547646756\n",
      "Iteration 15, x = [-2. -2. -5. -2. -4.  5. -1. -0. -2.  1.], gradient = 0.0, velocity = 0.0, tol = 0.00096597912464062\n",
      "Converged in 15 iterations\n",
      "Elapsed time: 0.008721351623535156\n"
     ]
    }
   ],
   "source": [
    "def gradientDecent(x, min_value=-np.inf, max_value=np.inf, tol=1e-3, max_iter=20, momentum=0.01, learning_rate=1):\n",
    "    x = np.array(x, dtype=float)\n",
    "    velocity = np.zeros_like(x)\n",
    "    previous_tol = 1 \n",
    "    stale = 0\n",
    "    for i in range(max_iter):\n",
    "        gradient = -fd_lambda(*x)\n",
    "        gradient = gradient.reshape(-1)        \n",
    "        # Update velocity\n",
    "        velocity = momentum * velocity + learning_rate * gradient\n",
    "        # Line search\n",
    "        cost = f_lambda(*x)\n",
    "        newCost = f_lambda(*(x+velocity))\n",
    "        a = 1\n",
    "        for j in range(10):\n",
    "            if newCost > cost * 0.95/a:\n",
    "                a *= 0.8\n",
    "                newCost = f_lambda(*(x+velocity*a))\n",
    "                print(f'Line search, a = {np.round(a, 2)}, cost = {np.round(cost, 2)}, newCost = {np.round(newCost, 2)}')\n",
    "            else:\n",
    "                velocity *= a\n",
    "                break\n",
    "        if newCost >= cost:\n",
    "            stale += 1\n",
    "        learning_rate *= 0.8\n",
    "        # Update x\n",
    "        x += velocity\n",
    "        # Clamp x to min and max values\n",
    "        x = np.clip(x, min_value, max_value)               \n",
    "        # Check if converged\n",
    "        current_tol = np.linalg.norm(gradient)\n",
    "        print(f'Iteration {i+1}, x = {np.round(x, 2)}, gradient = {np.round(np.linalg.norm(gradient), 2)}, velocity = {np.round(np.linalg.norm(velocity), 2)}, tol = {current_tol}')     \n",
    "        if round(previous_tol, 7) == round(current_tol, 7):\n",
    "            stale += 1\n",
    "            if stale == 2:\n",
    "                print(f'Converged in {i+1} iterations (Reached a plateau)')\n",
    "                return x\n",
    "        previous_tol = current_tol\n",
    "        if np.linalg.norm(gradient) < tol:\n",
    "            print(f'Converged in {i+1} iterations')\n",
    "            return x\n",
    "    return x\n",
    "\n",
    "# design variables, lagrange multipliers, and slack variables\n",
    "x = [*[-100]*variables]\n",
    "constraints = [-10, 10]\n",
    "start = time.time()\n",
    "result = gradientDecent(x, *constraints)\n",
    "print(f'Elapsed time: {time.time()-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute max step size to stay within bounds\n",
    "        aMax = 1\n",
    "        for j in range(variables):\n",
    "            if gradient[j] == 0:\n",
    "                continue\n",
    "            a = (min_value-x[j])/gradient[j] if gradient[j] < 0 else (max_value-x[j])/gradient[j]\n",
    "            aMax = min(aMax, a)\n",
    "# Line search\n",
    "        cost = f_lambda(*x)\n",
    "        newCost = f_lambda(*(x+gradient*a))\n",
    "        for j in range(10):\n",
    "            if newCost < cost * 0.99/a:\n",
    "                break\n",
    "            a *= 0.8\n",
    "            newCost = f_lambda(*(x+gradient*a))\n",
    "            print(f'Line search, a = {np.round(a, 2)}, cost = {np.round(cost, 2)}, newCost = {np.round(newCost, 2)}, aMax = {np.round(aMax, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "def IPM(x, constraints, max_iter=20, tol=1e-6):\n",
    "    x = np.array(x, dtype=float)\n",
    "    mu = 1.0\n",
    "    tolCurrent = np.inf\n",
    "    for i in range(max_iter):\n",
    "        # Newton's method\n",
    "        step, A, b = newtonSolver(x, constraints, mu)   \n",
    "        \n",
    "        # Max step size for design variables\n",
    "        aMax = 1\n",
    "        for j in range(constraintsNum):\n",
    "            a = (0.005-1)*x[variables+constraintsNum+j]/step[variables+constraintsNum+j]\n",
    "            if a > 0:\n",
    "                aMax = min(aMax, a)\n",
    "        aDesign = aMax\n",
    "\n",
    "        # Line search\n",
    "        ak = aMax\n",
    "        cost = f_lambda(*x[:variables])\n",
    "        newCost = f_lambda(*(x[:variables]+step.reshape(-1)[:variables]*ak))\n",
    "        while newCost > cost + 1e-4*ak*(fd_lambda(*x[:variables]).T @ step[:variables]):\n",
    "            ak *= 0.9\n",
    "            newCost = f_lambda(*(x[:variables]+step.reshape(-1)[:variables]*ak))\n",
    "\n",
    "        # Max step size for design variables\n",
    "        aMax = 1\n",
    "        for j in range(constraintsNum):\n",
    "            a = (0.005-1)*x[variables+j]/step[variables+j]\n",
    "            if a > 0:\n",
    "                aMax = min(aMax, a)\n",
    "        aLagrange = aMax\n",
    "\n",
    "        # Update x\n",
    "        step = step.reshape(-1)\n",
    "        step[:variables] = step[:variables]*ak\n",
    "        step[variables:variables+constraintsNum] = step[variables:variables+constraintsNum]*aLagrange\n",
    "        step[variables+constraintsNum:] = step[variables+constraintsNum:]*ak\n",
    "        x += step\n",
    "\n",
    "        # Check convergence\n",
    "        tolCurrent = np.linalg.norm(fd_lambda(*x[:variables]))\n",
    "        print(f'Iteration {i+1}, tol = {np.round(tolCurrent, 3)}, mu = {np.round(mu, 2)}, ak = {ak}, al = {aLagrange} ad = {aDesign} \\nx = {np.round(x, 2)}')\n",
    "        if tolCurrent < tol:\n",
    "            print('Converged')\n",
    "            return x\n",
    "        if ak < tol or aLagrange < tol:\n",
    "            print('Line search failed')\n",
    "            print(step)\n",
    "            return x\n",
    "        # Update mu\n",
    "        mu *= 0.5\n",
    "    return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
